{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– AI Agents Demo: Autonomous Data Cleaning & EDA\n",
    "\n",
    "Welcome! In this notebook we'll see AI agents in action â€” not just chatting, but **doing real work**.\n",
    "\n",
    "We'll go step by step:\n",
    "1. What's an LLM? (quick recap)\n",
    "2. What makes an agent different from a chatbot?\n",
    "3. Explore each piece of our data agent\n",
    "4. Run the full agent pipeline on a real CSV\n",
    "\n",
    "No prior AI experience needed. If you can read Python, you're good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup\n",
    "\n",
    "First, let's make sure everything is installed. Run the cell below once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Colab or a fresh environment, uncomment and run:\n",
    "# !pip install langchain langgraph langchain-openai langchain-anthropic langchain-groq langchain-aws pandas matplotlib seaborn chardet\n",
    "# git clone https://github.com/dcolinmorgan/EDAcleanr\n",
    "# cd EDAcleanr\n",
    "# uv pip install -e . --reinstall-package data-cleaning-eda-agent\n",
    "\n",
    "#change LLMs and providers in `src/tools/llm_config.py`\n",
    "\n",
    "# uv run eda-agent '/Users/apple/Downloads/spreadsheet.csv' --provider bedrock --region eu-north-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Set your API key here (pick ONE provider)\n",
    "# Option A: OpenAI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "# Option B: Anthropic\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\"\n",
    "\n",
    "# Option C: Groq (free tier available)\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"gsk_...\"\n",
    "\n",
    "# Option D: AWS Bedrock â€” uses your AWS credentials, no key needed here\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Quick LLM Recap\n",
    "\n",
    "An LLM (Large Language Model) is an AI trained on massive amounts of text. \n",
    "It predicts the next word â€” but does it so well that it can write code, answer questions, and reason about problems.\n",
    "\n",
    "Let's see one in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws sso login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2743057025.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_llm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Change provider/model to match your API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Options: \"openai\", \"anthropic\", \"groq\", \"bedrock\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPROVIDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bedrock\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.llm_config import get_llm\n",
    "\n",
    "# Change provider/model to match your API key\n",
    "# Options: \"openai\", \"anthropic\", \"groq\", \"bedrock\"\n",
    "PROVIDER = \"bedrock\"\n",
    "\n",
    "# For Bedrock, also pass region_name:\n",
    "# llm = get_llm(provider=\"bedrock\", region_name=\"eu-north-1\")\n",
    "llm = get_llm(provider=PROVIDER)\n",
    "\n",
    "print(f\"Using provider: {PROVIDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple LLM call â€” just a chatbot, not an agent yet\n",
    "response = llm.invoke(\"What are the 3 most common problems in messy CSV files? Be brief.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a **chatbot**: you ask, it answers. One shot.\n",
    "\n",
    "An **agent** goes further â€” it gets a goal, thinks about what to do, uses tools, checks results, and loops until done.\n",
    "\n",
    "```\n",
    "Agent = LLM + Tools + Memory + Reasoning Loop\n",
    "```\n",
    "\n",
    "Let's build up to that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Load a Messy CSV\n",
    "\n",
    "Our agent's first job: load a CSV file. This sounds simple, but real-world CSVs have encoding issues, weird delimiters, and other surprises.\n",
    "\n",
    "Our loader handles all of that automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.csv_loader import load_csv\n",
    "# https://www.kaggle.com/datasets/joannanplkrk/dirty-data-to-clean-whats-wrong-with-this-dataset\n",
    "# Point this to your CSV file\n",
    "CSV_PATH = \"../../../Downloads/archive/animal_data_dirty1.csv\"  # <-- change this!\n",
    "\n",
    "result = load_csv(CSV_PATH)\n",
    "\n",
    "if result[\"error\"]:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "else:\n",
    "    df = result[\"df\"]\n",
    "    print(f\"Loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Inspect â€” What's Wrong With This Data?\n",
    "\n",
    "Before cleaning, we need to know what's broken. Our inspection tools check for:\n",
    "- Missing values (per column)\n",
    "- Duplicate rows\n",
    "- Outliers (using the IQR method)\n",
    "- Mixed types in columns (numbers and text mixed together)\n",
    "- High cardinality (too many unique values in a category)\n",
    "- Zero variance columns (same value everywhere â€” useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.inspection import detect_issues, get_df_info\n",
    "\n",
    "# Profile the data\n",
    "profile = get_df_info(df)\n",
    "print(profile[:1000])  # first 1000 chars to keep it readable\n",
    "print(\"\\n... (truncated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect all issues\n",
    "issues = detect_issues(df)\n",
    "\n",
    "print(\"=== Issue Report ===\")\n",
    "print(\"\\nMissing values (% per column):\")\n",
    "for col, pct in issues[\"missing_pct\"].items():\n",
    "    if pct > 0:\n",
    "        print(f\"  {col}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nDuplicate rows: {issues['duplicate_count']}\")\n",
    "\n",
    "print(\"\\nOutliers (IQR method):\")\n",
    "for col, indices in issues[\"outliers\"].items():\n",
    "    print(f\"  {col}: {len(indices)} outlier(s)\")\n",
    "\n",
    "if issues[\"inconsistent_types\"]:\n",
    "    print(f\"\\nMixed types: {issues['inconsistent_types']}\")\n",
    "\n",
    "if issues[\"zero_variance\"]:\n",
    "    print(f\"\\nZero variance: {issues['zero_variance']}\")\n",
    "\n",
    "if issues[\"high_cardinality\"]:\n",
    "    print(f\"\\nHigh cardinality: {issues['high_cardinality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Clean â€” Fix the Problems\n",
    "\n",
    "Now we use our cleaning tools. In the full agent, the LLM decides which tools to call and in what order. \n",
    "Here we'll try them manually so you can see what each one does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape: (1011, 11)\n"
     ]
    }
   ],
   "source": [
    "from src.tools.cleaning import (\n",
    "    drop_duplicates,\n",
    "    fill_missing,\n",
    "    normalize_columns,\n",
    "    strip_string_values,\n",
    "    drop_useless_columns,\n",
    "    remove_outliers,\n",
    ")\n",
    "\n",
    "# Start with a copy\n",
    "cleaned = df.copy()\n",
    "print(f\"Starting shape: {cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 11 column name(s): 'Animal type' -> 'animal type', 'Country' -> 'country', 'Weight kg' -> 'weight kg', 'Body Length cm' -> 'body length cm', 'Gender' -> 'gender', 'Animal code' -> 'animal code', 'Latitude' -> 'latitude', 'Longitude' -> 'longitude', 'Animal name' -> 'animal name', 'Observation date' -> 'observation date', 'Data compiled by' -> 'data compiled by'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Normalize column names (lowercase, strip whitespace)\n",
    "cleaned, log = normalize_columns(cleaned)\n",
    "print(log.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripped whitespace from 6 string column(s).\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Strip whitespace from string values\n",
    "cleaned, log = strip_string_values(cleaned)\n",
    "print(log.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 167 duplicate rows.\n",
      "Shape after dedup: (844, 11)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Remove duplicate rows\n",
    "cleaned, log = drop_duplicates(cleaned)\n",
    "print(log.description)\n",
    "print(f\"Shape after dedup: {cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 useless column(s): animal code, animal name\n",
      "Shape after dropping useless columns: (844, 9)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Drop useless columns (>90% missing or zero variance)\n",
    "cleaned, log = drop_useless_columns(cleaned)\n",
    "print(log.description)\n",
    "print(f\"Shape after dropping useless columns: {cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'weight kg' using median strategy.\n",
      "Filled missing values in 'body length cm' using median strategy.\n",
      "Filled missing values in 'latitude' using median strategy.\n",
      "Filled missing values in 'longitude' using median strategy.\n",
      "\n",
      "Remaining missing values: 45\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Fill missing values in numeric columns with median\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = cleaned.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if cleaned[col].isna().sum() > 0:\n",
    "        cleaned, log = fill_missing(cleaned, col, \"median\")\n",
    "        print(log.description)\n",
    "\n",
    "print(f\"\\nRemaining missing values: {cleaned.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tool returns the cleaned DataFrame plus a log entry describing what it did. \n",
    "The agent collects all these logs for the final report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: EDA â€” Explore the Clean Data\n",
    "\n",
    "Now that the data is cleaner, let's analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Numeric Statistics ===\n",
      "         weight kg  body length cm    latitude   longitude\n",
      "count   844.000000      844.000000  844.000000  844.000000\n",
      "mean     46.290358       42.200237   49.238873   17.772974\n",
      "std     167.874269       62.741228    6.947500    3.772801\n",
      "min      -0.252000      -19.000000  -78.582973   11.074008\n",
      "25%       0.298750       19.000000   48.228756   14.382216\n",
      "50%       0.350000       21.000000   49.057679   18.849445\n",
      "75%       0.900000       23.000000   50.643518   20.558680\n",
      "max    1100.000000      350.000000   52.853843   34.896734\n"
     ]
    }
   ],
   "source": [
    "from src.tools.eda import describe_numeric, describe_categorical, compute_correlation, generate_plots\n",
    "\n",
    "# Numeric statistics\n",
    "print(\"=== Numeric Statistics ===\")\n",
    "print(describe_numeric(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Categorical Statistics ===\n",
      "Column: animal type\n",
      "animal type\n",
      "red squirrel       387\n",
      "hedgehog           274\n",
      "lynx                61\n",
      "European bison      49\n",
      "red squirrell       16\n",
      "lynx?               10\n",
      "red squirel         10\n",
      "European bisonâ„¢      6\n",
      "European bisson      4\n",
      "European buster      4\n",
      "\n",
      "Column: country\n",
      "country\n",
      "Poland            182\n",
      "Germany           173\n",
      "Slovakia          151\n",
      "Hungary           103\n",
      "Czech Republic    103\n",
      "Austria            74\n",
      "PL                 10\n",
      "HU                  8\n",
      "Hungry              7\n",
      "CZ                  5\n",
      "\n",
      "Column: gender\n",
      "gender\n",
      "male              423\n",
      "female            401\n",
      "not determined      5\n",
      "\n",
      "Column: observation date\n",
      "observation date\n",
      "01.03.2024    49\n",
      "02.03.2024    45\n",
      "06.04.2024    43\n",
      "02.04.2024    36\n",
      "04.03.2024    27\n",
      "24.03.2024    26\n",
      "21.03.2024    25\n",
      "07.03.2024    21\n",
      "05.04.2024    19\n",
      "08.04.2024    19\n",
      "\n",
      "Column: data compiled by\n",
      "data compiled by\n",
      "Anne Anthony     310\n",
      "Bob Bobson       256\n",
      "John Johnson     249\n",
      "James Johnson     29\n"
     ]
    }
   ],
   "source": [
    "# Categorical statistics (top 10 values per column)\n",
    "print(\"=== Categorical Statistics ===\")\n",
    "print(describe_categorical(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Correlation Matrix ===\n",
      "                weight kg  body length cm  latitude  longitude\n",
      "weight kg        1.000000        0.946469  0.096744   0.270548\n",
      "body length cm   0.946469        1.000000  0.077006   0.308109\n",
      "latitude         0.096744        0.077006  1.000000   0.049117\n",
      "longitude        0.270548        0.308109  0.049117   1.000000\n"
     ]
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "print(\"=== Correlation Matrix ===\")\n",
    "print(compute_correlation(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal type</th>\n",
       "      <th>country</th>\n",
       "      <th>weight kg</th>\n",
       "      <th>body length cm</th>\n",
       "      <th>gender</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>observation date</th>\n",
       "      <th>data compiled by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.057679</td>\n",
       "      <td>18.849445</td>\n",
       "      <td>03.01.2024</td>\n",
       "      <td>James Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.057679</td>\n",
       "      <td>18.849445</td>\n",
       "      <td>03.02.2024</td>\n",
       "      <td>James Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>European bison</td>\n",
       "      <td>Poland</td>\n",
       "      <td>930.000</td>\n",
       "      <td>335.0</td>\n",
       "      <td>male</td>\n",
       "      <td>52.828845</td>\n",
       "      <td>23.820144</td>\n",
       "      <td>01.03.2024</td>\n",
       "      <td>Anne Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>European bison</td>\n",
       "      <td>Poland</td>\n",
       "      <td>909.000</td>\n",
       "      <td>311.0</td>\n",
       "      <td>not determined</td>\n",
       "      <td>52.830509</td>\n",
       "      <td>23.826849</td>\n",
       "      <td>01.03.2024</td>\n",
       "      <td>Anne Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European bisonâ„¢</td>\n",
       "      <td>Poland</td>\n",
       "      <td>581.000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>female</td>\n",
       "      <td>52.834109</td>\n",
       "      <td>23.807093</td>\n",
       "      <td>01.03.2024</td>\n",
       "      <td>Anne Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0.900</td>\n",
       "      <td>23.0</td>\n",
       "      <td>male</td>\n",
       "      <td>47.510055</td>\n",
       "      <td>18.944356</td>\n",
       "      <td>7 May 2024</td>\n",
       "      <td>Anne Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>red squirrel</td>\n",
       "      <td>Poland</td>\n",
       "      <td>0.346</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>52.212001</td>\n",
       "      <td>21.033187</td>\n",
       "      <td>7 May 2024</td>\n",
       "      <td>Anne Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>female</td>\n",
       "      <td>49.561356</td>\n",
       "      <td>11.105334</td>\n",
       "      <td>7 May 2024</td>\n",
       "      <td>Bob Bobson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.500</td>\n",
       "      <td>17.0</td>\n",
       "      <td>female</td>\n",
       "      <td>49.561569</td>\n",
       "      <td>11.087046</td>\n",
       "      <td>7 May 2024</td>\n",
       "      <td>Bob Bobson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0.900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>female</td>\n",
       "      <td>47.509860</td>\n",
       "      <td>18.939943</td>\n",
       "      <td>8 May 2024</td>\n",
       "      <td>Anne Anthony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>844 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         animal type  country  weight kg  body length cm          gender  \\\n",
       "0                NaN      NaN      0.350            21.0             NaN   \n",
       "1                NaN      NaN      0.350            21.0             NaN   \n",
       "2     European bison   Poland    930.000           335.0            male   \n",
       "3     European bison   Poland    909.000           311.0  not determined   \n",
       "4    European bisonâ„¢   Poland    581.000           277.0          female   \n",
       "..               ...      ...        ...             ...             ...   \n",
       "839         hedgehog  Hungary      0.900            23.0            male   \n",
       "840     red squirrel   Poland      0.346            20.0          female   \n",
       "841         hedgehog  Germany      1.000            23.0          female   \n",
       "842         hedgehog  Germany      0.500            17.0          female   \n",
       "843         hedgehog  Hungary      0.900            16.0          female   \n",
       "\n",
       "      latitude  longitude observation date data compiled by  \n",
       "0    49.057679  18.849445       03.01.2024    James Johnson  \n",
       "1    49.057679  18.849445       03.02.2024    James Johnson  \n",
       "2    52.828845  23.820144       01.03.2024     Anne Anthony  \n",
       "3    52.830509  23.826849       01.03.2024     Anne Anthony  \n",
       "4    52.834109  23.807093       01.03.2024     Anne Anthony  \n",
       "..         ...        ...              ...              ...  \n",
       "839  47.510055  18.944356       7 May 2024     Anne Anthony  \n",
       "840  52.212001  21.033187       7 May 2024     Anne Anthony  \n",
       "841  49.561356  11.105334       7 May 2024       Bob Bobson  \n",
       "842  49.561569  11.087046       7 May 2024       Bob Bobson  \n",
       "843  47.509860  18.939943       8 May 2024     Anne Anthony  \n",
       "\n",
       "[844 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display plots\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "fig_paths = generate_plots(cleaned, \"output/figures\")\n",
    "print(f\"Generated {len(fig_paths)} figures\\n\")\n",
    "\n",
    "# Show the plots inline\n",
    "for path in fig_paths:\n",
    "    print(Path(path).stem.replace('_', ' ').title())\n",
    "    display(Image(filename=path, width=500))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: The Full Agent â€” Putting It All Together\n",
    "\n",
    "So far we called each tool manually. The real power of an agent is that the **LLM decides** what to do.\n",
    "\n",
    "Our LangGraph workflow connects all the pieces:\n",
    "\n",
    "```\n",
    "Load CSV -> Inspect -> Decide Cleaning -> Clean (loop) -> EDA -> Report\n",
    "```\n",
    "\n",
    "The LLM:\n",
    "- Reviews the issue report and decides which cleaning tools to call\n",
    "- Can loop back for more cleaning if needed\n",
    "- Analyzes EDA results and writes insights\n",
    "\n",
    "This is the **ReAct pattern**: Reason + Act, in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graph import build_graph\n",
    "from src.models import AgentState\n",
    "\n",
    "# Build the agent graph\n",
    "graph = build_graph(llm)\n",
    "\n",
    "# Prepare the initial state\n",
    "initial_state: AgentState = {\n",
    "    \"file_path\": CSV_PATH,\n",
    "    \"cleaning_iteration\": 0,\n",
    "    \"max_cleaning_iterations\": 3,\n",
    "    \"cleaning_log\": [],\n",
    "    \"errors\": [],\n",
    "    \"reasoning_log\": [],\n",
    "    \"insights\": [],\n",
    "    \"figure_paths\": [],\n",
    "    \"needs_more_cleaning\": False,\n",
    "    \"df\": None,\n",
    "    \"original_shape\": None,\n",
    "    \"profile\": None,\n",
    "    \"issue_report\": None,\n",
    "    \"eda_results\": None,\n",
    "    \"report_path\": None,\n",
    "}\n",
    "\n",
    "print(\"Running the full agent pipeline...\")\n",
    "print(\"(This may take 30-60 seconds depending on the LLM)\\n\")\n",
    "\n",
    "result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "if result.get(\"report_path\"):\n",
    "    print(f\"Report saved to: {result['report_path']}\")\n",
    "else:\n",
    "    print(\"Report was not generated.\")\n",
    "\n",
    "if result.get(\"errors\"):\n",
    "    print(f\"\\nErrors encountered: {len(result['errors'])}\")\n",
    "    for err in result[\"errors\"]:\n",
    "        print(f\"  - {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the agent's reasoning log â€” this shows HOW the agent thought\n",
    "print(\"=== Agent Reasoning Log ===\")\n",
    "for entry in result.get(\"reasoning_log\", []):\n",
    "    agent = entry.get(\"agent\", \"unknown\")\n",
    "    reasoning = entry.get(\"reasoning\", \"\")[:200]  # truncate for readability\n",
    "    print(f\"\\n[{agent}]\")\n",
    "    print(f\"  {reasoning}\")\n",
    "    if len(entry.get(\"reasoning\", \"\")) > 200:\n",
    "        print(\"  ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated report\n",
    "from IPython.display import Markdown\n",
    "\n",
    "if result.get(\"report_path\"):\n",
    "    with open(result[\"report_path\"], \"r\") as f:\n",
    "        report_content = f.read()\n",
    "    display(Markdown(report_content))\n",
    "else:\n",
    "    print(\"No report to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: What Just Happened?\n",
    "\n",
    "Let's recap what the agent did **autonomously**:\n",
    "\n",
    "1. **Loaded** the CSV (handled encoding, delimiters)\n",
    "2. **Inspected** the data (found missing values, duplicates, outliers, etc.)\n",
    "3. **Decided** what to clean (the LLM reviewed the issues and made a plan)\n",
    "4. **Cleaned** the data (called the right tools with the right parameters)\n",
    "5. **Analyzed** the clean data (statistics, correlations, charts)\n",
    "6. **Wrote** a report with insights\n",
    "\n",
    "You didn't tell it *how* to clean â€” it figured that out from the data.\n",
    "\n",
    "That's the difference between a chatbot and an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Try It Yourself\n",
    "\n",
    "Things to experiment with:\n",
    "\n",
    "- **Different CSV files** â€” change `CSV_PATH` above and re-run\n",
    "- **Different LLM providers** â€” change `PROVIDER` to `\"anthropic\"`, `\"groq\"`, or `\"bedrock\"`\n",
    "- **More cleaning iterations** â€” change `max_cleaning_iterations` to 5\n",
    "- **From the command line** â€” run in your terminal:\n",
    "\n",
    "```bash\n",
    "uv run eda-agent your_data.csv --provider openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Limits & Gotchas\n",
    "\n",
    "Agents are powerful but not perfect:\n",
    "\n",
    "- **Hallucinations** â€” the LLM might suggest cleaning steps that don't make sense\n",
    "- **Cost** â€” each run makes several LLM API calls (a few cents with GPT-4o-mini, more with larger models)\n",
    "- **Unsafe code** â€” in production, you'd want sandboxing around any LLM-generated code\n",
    "- **Not deterministic** â€” running twice on the same data may produce slightly different results\n",
    "\n",
    "These are active research areas. The tech is moving fast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
